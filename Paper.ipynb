{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import warnings\n",
    "import vl_convert as vlc\n",
    "import cairosvg\n",
    "warnings.filterwarnings('ignore')\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(prefix, expt_name, since=0):\n",
    "    results_file = f\"results/infer_bench_perf/{prefix}_{expt_name}.csv\"\n",
    "    if expt_name.startswith(\"High\"):\n",
    "        usage = \"3. High\"\n",
    "    if expt_name == \"Medium\":\n",
    "        usage = \"2. Medium\"\n",
    "    if expt_name == \"Low\":\n",
    "        usage = \"1. Low\" if prefix == \"pre\" else \"4. Low\"\n",
    "    columns = [\"since\", \"latency\", \"exec_mode\"]\n",
    "    results = pd.read_csv(results_file, names=columns)\n",
    "    results[\"latency\"] = results.latency * 1000.0 # Convert to ms.\n",
    "    results[\"since\"] = results[\"since\"] / 1000.0 + since\n",
    "    results[\"Usage\"] = [usage for _ in range(0, len(results))]\n",
    "    p99 = results.latency.quantile(0.99)\n",
    "    results = results[results.latency < p99]\n",
    "    return results\n",
    "\n",
    "\n",
    "res1 = read_results(\"pre\", \"Low\", 0)\n",
    "low_avg = res1.latency.mean()\n",
    "res2 = read_results(\"pre\", \"Medium\", res1.since.max())\n",
    "medium_avg = res2.latency.mean()\n",
    "res3 = read_results(\"pre\", \"High(10)\", res2.since.max())\n",
    "high_avg = res3.latency.mean()\n",
    "pre_res = pd.concat([res1, res2, res3])\n",
    "res4 = read_results(\"post\", \"Low\", res3.since.max())\n",
    "res = pd.concat([res1, res2, res3, res4])\n",
    "\n",
    "\n",
    "# print(\"Latencies\")\n",
    "# chart1.display()\n",
    "\n",
    "# expt_dir = \"figures/inference\"\n",
    "# svg_str = vlc.vegalite_to_svg(chart1.to_json())\n",
    "# cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/latencies.pdf\")\n",
    "\n",
    "res[\"since\"] = pd.to_timedelta(res.since, unit='s')\n",
    "res = res[[\"since\", \"latency\"]].groupby(pd.Grouper(key=\"since\", freq=\"1min\")).median()\n",
    "res[\"since\"] = res.index.total_seconds() / 60 + 1\n",
    "\n",
    "chart1 = alt.Chart(res).mark_line().encode(\n",
    "    x = alt.X('since', title='Time since Start'),\n",
    "    y = alt.Y('latency', title='End-to-end lantency (ms)'),\n",
    ").properties(\n",
    "    # title = \"Read performance distribution\",\n",
    "    width=300,\n",
    "    height=300\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "chart1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg cost per month.\n",
    "def comparison_nums(avg_latency, median_latency, mode):\n",
    "    if mode == \"Low\":\n",
    "        reqs_per_sec = 1\n",
    "    if mode == \"Medium\":\n",
    "        reqs_per_sec = 50\n",
    "    if mode == \"High\":\n",
    "        reqs_per_sec = 200\n",
    "    # Reqs in an month.\n",
    "    num_hours = 24 * 30\n",
    "    total_reqs = 3600.0 * reqs_per_sec * num_hours\n",
    "    print(total_reqs)\n",
    "    pure_lambda_latency = low_median # Same for all other modes.\n",
    "    print(pure_lambda_latency)\n",
    "    pure_lambda_cost = total_reqs * ((low_avg - 15.0) * 4 * 0.0000000167 + 0.2 / 1e6) # 4GB of mem. \n",
    "    pure_lambda_user_cost = total_reqs * low_avg * 0.5 * 0.0000000167\n",
    "    visc_latency = median_latency\n",
    "    if mode == \"Low\":\n",
    "        visc_cost = pure_lambda_cost\n",
    "    if mode == \"Medium\":\n",
    "        visc_cost = num_hours * 0.015 * 2.0 * 2.0 # 2vcpus (x2 for excess sizing).\n",
    "    if mode == \"High\":\n",
    "        visc_cost  = num_hours * 9 * (0.015 * 2.0 * 2.0) # Like above, but with 3 instances.\n",
    "    visc_user_cost = total_reqs * avg_latency * 0.5 * 0.0000000167\n",
    "    \n",
    "    systems = []\n",
    "    modes = []\n",
    "    latencies = []\n",
    "    compute_costs = []\n",
    "    overall_costs = []\n",
    "    if mode == \"Low\":\n",
    "        mode = \"1. Low\"\n",
    "    if mode == \"Medium\":\n",
    "        mode = \"2. Medium\"\n",
    "    if mode == \"High\":\n",
    "        mode = \"3. High\"\n",
    "    systems.append(\"Pure Lambda\")\n",
    "    modes.append(mode)\n",
    "    latencies.append(pure_lambda_latency)\n",
    "    compute_costs.append(pure_lambda_cost)\n",
    "    overall_costs.append(pure_lambda_cost + pure_lambda_user_cost)\n",
    "    systems.append(\"VISC Inference\")\n",
    "    modes.append(mode)\n",
    "    latencies.append(visc_latency)\n",
    "    compute_costs.append(visc_cost)\n",
    "    overall_costs.append(visc_cost + visc_user_cost)\n",
    "    return pd.DataFrame({\n",
    "        \"systems\": systems,\n",
    "        \"modes\": modes,\n",
    "        \"latencies\": latencies,\n",
    "        \"compute_costs\": compute_costs,\n",
    "        \"overall_costs\": overall_costs,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "low_median = res1.latency.quantile(0.5)\n",
    "medium_median = res2.latency.quantile(0.5)\n",
    "high_median = res3.latency.quantile(0.5)\n",
    "cres1 = comparison_nums(low_avg, low_median, \"Low\")\n",
    "cres2 = comparison_nums(medium_avg, medium_median, \"Medium\")\n",
    "cres3 = comparison_nums(high_avg, high_median, \"High\")\n",
    "cres = pd.concat([cres1, cres2, cres3])\n",
    "\n",
    "chart1 = alt.Chart(data=cres).mark_bar().encode(\n",
    "    x=alt.X(\"systems\", title=\"\"),\n",
    "    y=alt.Y(\"compute_costs\", title=\"Monthly Cost\"),\n",
    "    column=alt.Column(\"modes\", title=\"Utilization\"),\n",
    "    color=alt.Color(\"systems\", legend=None)\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=100,\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "chart2 = alt.Chart(data=cres).mark_bar().encode(\n",
    "    x=alt.X(\"systems\", title=\"\"),\n",
    "    y=alt.Y(\"overall_costs\", title=\"Monthly Cost\"),\n",
    "    column=alt.Column(\"modes\", title=\"Utilization\"),\n",
    "    color=alt.Color(\"systems\", legend=None)\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=100,\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "chart3 = alt.Chart(data=cres).mark_bar().encode(\n",
    "    x=alt.X(\"systems\", title=\"\"),\n",
    "    y=alt.Y(\"latencies\", title=\"Latency\"),\n",
    "    column=alt.Column(\"modes\", title=\"Utilization\"),\n",
    "    color=alt.Color(\"systems\", legend=None)\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=100,\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "print(\"Compute Costs\")\n",
    "chart1.display()\n",
    "print(\"Overall Costs\")\n",
    "chart2.display()\n",
    "print(\"Latencies\")\n",
    "chart3.display()\n",
    "\n",
    "expt_dir = \"figures/inference\"\n",
    "svg_str = vlc.vegalite_to_svg(chart1.to_json())\n",
    "cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/compute_cost_comparison.pdf\")\n",
    "svg_str = vlc.vegalite_to_svg(chart2.to_json())\n",
    "cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/overall_cost_comparison.pdf\")\n",
    "svg_str = vlc.vegalite_to_svg(chart3.to_json())\n",
    "cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/latency_comparison.pdf\")\n",
    "\n",
    "cres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "52.790602 * (1 + 0.1585189538092405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(prefix, expt_name, since=0):\n",
    "    results_file = f\"results/microactor_bench/{prefix}_{expt_name}.csv\"\n",
    "    if expt_name.startswith(\"High\"):\n",
    "        usage = \"3. High\"\n",
    "    if expt_name == \"Medium\":\n",
    "        usage = \"2. Medium\"\n",
    "    if expt_name == \"Low\":\n",
    "        usage = \"1. Low\" if prefix == \"pre\" else \"4. Low\"\n",
    "    columns = [\"since\", \"latency\", \"operation\"]\n",
    "    results = pd.read_csv(results_file, names=columns)\n",
    "    results[\"latency\"] = results.latency * 1000.0 # Convert to ms.\n",
    "    results[\"since\"] = results[\"since\"] / 1000.0 + since\n",
    "    results[\"Usage\"] = [usage for _ in range(0, len(results))]\n",
    "    p99 = results.latency.quantile(0.99)\n",
    "    results = results[results.latency < p99]\n",
    "    return results\n",
    "\n",
    "# Compute results.\n",
    "res1 = read_results(\"pre\", \"Low\", 0)\n",
    "low_avg = 2 * res1.latency.mean() # One retrieve and one increment request.\n",
    "res2 = read_results(\"pre\", \"Medium\", res1.since.max())\n",
    "medium_avg = 2 * res2.latency.mean()\n",
    "res3 = read_results(\"pre\", \"High(10)\", res2.since.max())\n",
    "high_avg = 2 * res3.latency.mean()\n",
    "pre_res = pd.concat([res1, res2, res3])\n",
    "res4 = read_results(\"post\", \"Low\", res3.since.max())\n",
    "res = pd.concat([res1, res2, res3, res4])\n",
    "\n",
    "chart1 = alt.Chart(res[res.operation == \"Retrieve\"]).mark_boxplot(extent=\"min-max\", size=50).encode(\n",
    "    x = alt.X('Usage', title='Utilization'),\n",
    "    y = alt.Y('latency', scale=alt.Scale(type=\"symlog\"), axis=alt.Axis(values=[0, 1, 10, 100, 1000]), title='End-to-end lantency (ms)'),\n",
    ").properties(\n",
    "    # title = \"Read performance distribution\",\n",
    "    width=300,\n",
    "    height=300\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "chart2 = alt.Chart(res[res.operation == \"Increment\"]).mark_boxplot(extent=\"min-max\", size=50).encode(\n",
    "    x = alt.X('Usage', title='Utilization'),\n",
    "    y = alt.Y('latency', scale=alt.Scale(type=\"symlog\"), axis=alt.Axis(values=[0, 1, 10, 100, 1000]), title='End-to-end lantency (ms)'),\n",
    ").properties(\n",
    "    # title = \"Read performance distribution\",\n",
    "    width=300,\n",
    "    height=300\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "print(\"Retrieve Latencies\")\n",
    "chart1.display()\n",
    "print(\"Increment Latencies\")\n",
    "chart2.display()\n",
    "\n",
    "\n",
    "expt_dir = \"figures/actor/\"\n",
    "svg_str = vlc.vegalite_to_svg(chart1.to_json())\n",
    "cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/retrieve_latencies.pdf\")\n",
    "svg_str = vlc.vegalite_to_svg(chart2.to_json())\n",
    "cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/increment_latencies.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Avg cost per month.\n",
    "def comparison_nums(avg_latency, median_latency, mode):\n",
    "    if mode == \"Low\":\n",
    "        reqs_per_sec = 1\n",
    "    if mode == \"Medium\":\n",
    "        reqs_per_sec = 100\n",
    "    if mode == \"High\":\n",
    "        reqs_per_sec = 1000\n",
    "    # Reqs in an month.\n",
    "    num_hours = 24 * 30\n",
    "    total_reqs = 3600.0 * reqs_per_sec * num_hours\n",
    "    print(total_reqs)\n",
    "    pure_lambda_latency = low_median # Same for all other modes.\n",
    "    print(pure_lambda_latency)\n",
    "    pure_lambda_cost = total_reqs * ((low_avg - 10.0) * 4 * 0.0000000167 + 0.2 / 1e6) # 4GB of mem.\n",
    "    pure_lambda_user_cost = total_reqs * low_avg * 0.5 * 0.0000000167\n",
    "    pure_ecs_latency = medium_median\n",
    "    pure_ecs_cost = num_hours * 0.015 * 2.0 # 2vcpus.\n",
    "    pure_ecs_user_cost = total_reqs * medium_avg * 0.5 * 0.0000000167\n",
    "    visc_latency = median_latency\n",
    "    if mode == \"Low\":\n",
    "        visc_cost = pure_lambda_cost\n",
    "    if mode == \"Medium\":\n",
    "        visc_cost = pure_ecs_cost\n",
    "    if mode == \"High\":\n",
    "        visc_cost  = num_hours * 0.015 * (2.0 + 6*0.25) # 2vcpus and 6 times 0.25vcpus.\n",
    "    visc_user_cost = total_reqs * avg_latency * 0.5 * 0.0000000167\n",
    "    \n",
    "    systems = []\n",
    "    modes = []\n",
    "    latencies = []\n",
    "    compute_costs = []\n",
    "    overall_costs = []\n",
    "    if mode == \"Low\":\n",
    "        mode = \"1. Low\"\n",
    "    if mode == \"Medium\":\n",
    "        mode = \"2. Medium\"\n",
    "    if mode == \"High\":\n",
    "        mode = \"3. High\"\n",
    "    if \"High\" not in mode:\n",
    "        systems.append(\"Lambda\")\n",
    "        modes.append(mode)\n",
    "        latencies.append(pure_lambda_latency)\n",
    "        compute_costs.append(pure_lambda_cost)\n",
    "        overall_costs.append(pure_lambda_cost + pure_lambda_user_cost)\n",
    "    systems.append(\"Container\")\n",
    "    modes.append(mode)\n",
    "    latencies.append(pure_ecs_latency)\n",
    "    compute_costs.append(pure_ecs_cost)\n",
    "    overall_costs.append(pure_ecs_cost + pure_ecs_user_cost)\n",
    "    systems.append(\"VISC\")\n",
    "    modes.append(mode)\n",
    "    latencies.append(visc_latency)\n",
    "    compute_costs.append(visc_cost)\n",
    "    overall_costs.append(visc_cost + visc_user_cost)\n",
    "    return pd.DataFrame({\n",
    "        \"systems\": systems,\n",
    "        \"modes\": modes,\n",
    "        \"latencies\": latencies,\n",
    "        \"compute_costs\": compute_costs,\n",
    "        \"overall_costs\": overall_costs,\n",
    "    })\n",
    "\n",
    "# Compute medians.\n",
    "low_median = res1[res1[\"operation\"] == \"Retrieve\"].latency.quantile(0.5) + res1[res1[\"operation\"] == \"Increment\"].latency.quantile(0.5)\n",
    "medium_median = res2[res2[\"operation\"] == \"Retrieve\"].latency.quantile(0.5) + res2[res2[\"operation\"] == \"Increment\"].latency.quantile(0.5)\n",
    "high_median = res3[res3[\"operation\"] == \"Retrieve\"].latency.quantile(0.5) + res3[res3[\"operation\"] == \"Increment\"].latency.quantile(0.5)\n",
    "cres1 = comparison_nums(low_avg, low_median, \"Low\")\n",
    "cres2 = comparison_nums(medium_avg, medium_median, \"Medium\")\n",
    "cres3 = comparison_nums(high_avg, high_median, \"High\")\n",
    "cres = pd.concat([cres1, cres2, cres3])\n",
    "\n",
    "chart1 = alt.Chart(data=cres).mark_bar().encode(\n",
    "    x=alt.X(\"systems\", title=\"\"),\n",
    "    y=alt.Y(\"compute_costs\", title=\"Monthly Cost\"),\n",
    "    column=alt.Column(\"modes\", title=\"Utilization\"),\n",
    "    color=alt.Color(\"systems\", legend=None)\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=100,\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "chart2 = alt.Chart(data=cres).mark_bar().encode(\n",
    "    x=alt.X(\"systems\", title=\"\"),\n",
    "    y=alt.Y(\"overall_costs\", title=\"Monthly Cost\"),\n",
    "    column=alt.Column(\"modes\", title=\"Utilization\"),\n",
    "    color=alt.Color(\"systems\", legend=None)\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=100,\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "chart3 = alt.Chart(data=cres).mark_bar().encode(\n",
    "    x=alt.X(\"systems\", title=\"\"),\n",
    "    y=alt.Y(\"latencies\", title=\"Latency\"),\n",
    "    column=alt.Column(\"modes\", title=\"Utilization\"),\n",
    "    color=alt.Color(\"systems\", legend=None)\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=100,\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "print(\"Compute Costs\")\n",
    "chart1.display()\n",
    "print(\"Overall Costs\")\n",
    "chart2.display()\n",
    "print(\"Latencies\")\n",
    "chart3.display()\n",
    "\n",
    "expt_dir = \"figures/actor\"\n",
    "svg_str = vlc.vegalite_to_svg(chart1.to_json())\n",
    "cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/compute_cost_comparison.pdf\")\n",
    "svg_str = vlc.vegalite_to_svg(chart2.to_json())\n",
    "cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/overall_cost_comparison.pdf\")\n",
    "svg_str = vlc.vegalite_to_svg(chart3.to_json())\n",
    "cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/latency_comparison.pdf\")\n",
    "\n",
    "cres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "260.138862/123.920105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8 / 2.32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KV Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(prefix, expt_name, since=0):\n",
    "    results_file = f\"results/kv_bench_cost_only/{prefix}_{expt_name}.csv\"\n",
    "    if expt_name.startswith(\"High\"):\n",
    "        usage = \"3. High\"\n",
    "    if expt_name == \"Medium\":\n",
    "        usage = \"2. Medium\"\n",
    "    if expt_name == \"Low\":\n",
    "        usage = \"1. Low\" if prefix == \"pre\" else \"4. Low\"\n",
    "    columns = [\"since\", \"latency\", \"exec_mode\"]\n",
    "    results = pd.read_csv(results_file, names=columns)\n",
    "    results[\"latency\"] = results.latency * 1000.0 # Convert to ms.\n",
    "    results[\"since\"] = results[\"since\"] / 1000.0 + since\n",
    "    results[\"Usage\"] = [usage for _ in range(0, len(results))]\n",
    "    p99 = results.latency.quantile(0.99)\n",
    "    results = results[results.latency < p99]\n",
    "    return results\n",
    "\n",
    "\n",
    "res1 = read_results(\"kvpre\", \"Low\", 0)\n",
    "low_avg = res1.latency.mean()\n",
    "res2 = read_results(\"kvpre\", \"Medium\", res1.since.max())\n",
    "medium_avg = res2.latency.mean()\n",
    "res3 = read_results(\"kvpre\", \"High(10)\", res2.since.max())\n",
    "high_avg = res3.latency.mean()\n",
    "pre_res = pd.concat([res1, res2, res3])\n",
    "res4 = read_results(\"kvpost\", \"Low\", res3.since.max())\n",
    "res = pd.concat([res1, res2, res3, res4])\n",
    "res = res[res[\"exec_mode\"] == \"Read\"]\n",
    "\n",
    "# print(\"Latencies\")\n",
    "# chart1.display()\n",
    "\n",
    "# expt_dir = \"figures/inference\"\n",
    "# svg_str = vlc.vegalite_to_svg(chart1.to_json())\n",
    "# cairosvg.svg2pdf(bytestring=svg_str, write_to=f\"{expt_dir}/latencies.pdf\")\n",
    "\n",
    "res[\"since\"] = pd.to_timedelta(res.since, unit='s')\n",
    "res = res[[\"since\", \"latency\"]].groupby(pd.Grouper(key=\"since\", freq=\"1min\")).median()\n",
    "res[\"since\"] = res.index.total_seconds() / 60 + 1\n",
    "\n",
    "chart1 = alt.Chart(res).mark_line().encode(\n",
    "    x = alt.X('since', title='Time since Start'),\n",
    "    y = alt.Y('latency', title='End-to-end lantency (ms)'),\n",
    ").properties(\n",
    "    # title = \"Read performance distribution\",\n",
    "    width=300,\n",
    "    height=300\n",
    ").configure_axis(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12,\n",
    ")\n",
    "\n",
    "chart1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.iloc[160:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
